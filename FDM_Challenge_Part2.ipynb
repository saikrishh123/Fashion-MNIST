{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Foundations of Data Mining: Fashion-MNIST Challenge\n",
    "\n",
    "Please complete all assignments in this notebook. You should submit this notebook, as well as a PDF version (See File > Download as)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from preamble import *\n",
    "plt.rcParams['figure.dpi'] = 200 # This controls the size of your figures\n",
    "plt.rcParams['savefig.dpi'] = 200 # This controls the size of your figures\n",
    "# Comment out and restart notebook if you only want the last output of each cell.\n",
    "InteractiveShell.ast_node_interactivity = \"all\" \n",
    "import sklearn.decomposition as deco\n",
    "from sklearn.cluster import KMeans \n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fashion-MNIST\n",
    "The [Fashion-MNIST dataset](https://www.openml.org/d/40996) contains 70,000 images of Zalando fashion products, classified into 10 types of clothing, each represented by 28 by 28 pixel values. We can easily download it from OpenML and visualize one of the examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fmnist_classes = {0:\"T-shirt/top\", 1: \"Trouser\", 2: \"Pullover\", 3: \"Dress\", 4: \"Coat\", 5: \"Sandal\", \n",
    "                  6: \"Shirt\", 7: \"Sneaker\", 8: \"Bag\", 9: \"Ankle boot\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fmnist_data = oml.datasets.get_dataset(40996) # Download MNIST data\n",
    "# Get the predictors X and the labels y\n",
    "X, y = fmnist_data.get_data(target=fmnist_data.default_target_attribute); "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build a list of figures for plotting\n",
    "def buildFigureList(fig, subfiglist, titles, length):\n",
    "    \n",
    "    for i in range(0,length):\n",
    "        pixels = np.array(subfiglist[i], dtype='float')\n",
    "        pixels = pixels.reshape((28, 28))\n",
    "        a=fig.add_subplot(1,length,i+1)\n",
    "        imgplot =plt.imshow(pixels, cmap='gray_r')\n",
    "        a.set_title(titles[i], fontsize=6)\n",
    "        a.axes.get_xaxis().set_visible(False)\n",
    "        a.axes.get_yaxis().set_visible(False)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subfiglist = []\n",
    "titles=[]\n",
    "\n",
    "for i in range(0,10):\n",
    "    subfiglist.append(X[i])\n",
    "    titles.append(i)\n",
    "\n",
    "buildFigureList(plt.figure(1),subfiglist, titles, 10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Question 2. Analyzing image data with neural embedding\n",
    "\n",
    "*In this part of the assignment, rather than working on the whole dataset you will implement representation learning on one part of the data and analyze the second part of the data with the learned representations.*\n",
    "\n",
    "Use the provided code to split the training dataset in two subset based on their class labels. Dataset 1, containing classes 0 to 4 and Dataset 2 classes 5 to 9. \n",
    "\n",
    "### a ) Develop a model for learning representations (4 points)\n",
    "\n",
    "Develop a convolutional neural network model for classification on Dataset 1 using the Keras python library.\n",
    "\n",
    "You are free to choose your model architecture such that:\n",
    "- You need to justify the decisions for selecting the layers, activation functions and loss function. (Add a text cell where you can write your justification)\n",
    "- Your model must have one dense layer with 64 neurons and ReLU activation that is not the first nor the last layer in the model. We will refer to this layer as a 'neural code' (set **name='neural_codes'** parameter in your code for that layer).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do not modify this cell\n",
    "# Extra imports for kears layers, matplotlib and nearestneigbors\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout, Conv2D, MaxPooling2D, Flatten, BatchNormalization\n",
    "from keras.utils import to_categorical\n",
    "from keras import backend as K\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.neighbors import NearestNeighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Do not modify this cell\n",
    "# Load and reshape the data\n",
    "img_rows, img_cols, chns = 28, 28, 1\n",
    "n_classes = 10\n",
    "\n",
    "x_train = X\n",
    "y_train = y\n",
    "\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    x_train = x_train.reshape(x_train.shape[0], chns, img_rows, img_cols)\n",
    "    #x_test = x_test.reshape(x_test.shape[0], chns, img_rows, img_cols)\n",
    "    input_shape = (chns, img_rows, img_cols)\n",
    "else:\n",
    "    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, chns)\n",
    "    #x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, chns)\n",
    "    input_shape = (img_rows, img_cols, chns)\n",
    "\n",
    "    y_train = to_categorical(y_train, n_classes)\n",
    "\n",
    "    \n",
    "# Split the data in two datasets \n",
    "indexes1 = np.where(np.argmax(y_train, axis=1) <= 4)\n",
    "indexes2 = np.where(np.argmax(y_train, axis=1) > 4)\n",
    "dataset_1 = x_train[indexes1]\n",
    "y_dataset1 = y_train[indexes1]\n",
    "dataset_2 = x_train[indexes2]\n",
    "y_dataset2 = y_train[indexes2]\n",
    "\n",
    "print (\"Dataset 1 shape: \", dataset_1.shape)    \n",
    "print (\"Dataset 2 shape: \", dataset_2.shape)    \n",
    "print(\"Dataset 1 labels shape: \", y_dataset1.shape)\n",
    "print(\"Dataset 2 labels shape: \", y_dataset2.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement your model here\n",
    "\n",
    "# model = \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do not modify this cell\n",
    "# Execute this cell before training!\n",
    "# This is the model for extracting the image neural codes from the trained model\n",
    "neural_codes_model = Model(inputs=model.input, outputs=model.get_layer(\"neural_codes\").output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trainning loop \n",
    "# given parameters are just a suggestion\n",
    "batch_size = 64\n",
    "epochs = 10\n",
    "\n",
    "model.fit(dataset_1, y_dataset1,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          validation_split=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### b) Generate neural codes (1 point) \n",
    "Process all the images from Data set 2 with the trained model from **a)** and save the activations from the 'neural code' layer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement here\n",
    "# Note: Using neural_codes_model compute the neural code for the images in dataset_2 \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c) Analyze the neural codes (3 points) \n",
    "\n",
    "Implement the following analysis of the neural codes computed in ** b) **:\n",
    "\n",
    "- Compute and show the mean and the first two principle components as images (see note below)\n",
    "- Make a 2-dimensional scatter plot of the transformed data\n",
    "- Compute and show a small number of samples along each of the two main axes as images\n",
    "- Compute and show a sample of input images along each of the two main axes as images\n",
    "- Compare the results of this analysis with the results of the analysis in part one where you worked on the data in the high dimensional (image) space. \n",
    "\n",
    "*Note: To produce an image from a arbitrary neural code use nearest neighbor to find the closest neural code from the training dataset (code is provided in the next cell)* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do not modify this cell\n",
    "# This code will give you a method for getting the index of the closest neural code neighbor \n",
    "# (see example code in the next cell)\n",
    "neigh = NearestNeighbors(n_neighbors=5, p=2)\n",
    "neigh.fit(neural_codes)\n",
    "\n",
    "def get_closest_neighbor(code):\n",
    "    distances, indexes = neigh.kneighbors([code])\n",
    "    return indexes[0, 1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example code for finding a neighbors based on the neural codes \n",
    "\n",
    "# Select a random image from the dataset \n",
    "index = 123\n",
    "# Get its neural code\n",
    "print(\"Neural code: \", neural_codes[index])\n",
    "# Get its closest neighbor\n",
    "index_neighbor = get_closest_neighbor(neural_codes[index])\n",
    "\n",
    "# Build the figure\n",
    "subfiglist = []\n",
    "titles = []\n",
    "subfiglist.append(np.squeeze(dataset_2[index], axis=2))\n",
    "titles.append(fmnist_classes[np.argmax(y_dataset2[index])])\n",
    "subfiglist.append(np.squeeze(dataset_2[index_neighbor], axis=2))\n",
    "titles.append(fmnist_classes[np.argmax(y_dataset2[index_neighbor])])\n",
    "\n",
    "buildFigureList(plt.figure(1),subfiglist, titles, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Develop solution here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### d) Analyze a cluster computed by k-means (2 Points)\n",
    "- Run k-means on neural code from Dataset 2 with k=5 using k-means++ and random_state=0\n",
    "- Compute and show a confusion matrix of the clusters with respect to the original labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
